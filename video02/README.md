# python-data-analysis
Python数据分析

参考视频：
吴恩达-机器学习

1-绪论：初识机器学习
    机器学习
    监督学习：数据集中的每个样本都有相应的“正确答案”，再根据这些样本做出预测。
        回归问题、分类问题等
        例：垃圾邮件处理、癌症判断
    无监督学习：数据集中没有任何的标签或者是有相同的标签，已知数据集不知如何处理。
        聚类应用等
        例：新闻事件推荐
    鸡尾酒会问题：音频分离与合成
    demo-cocktail party problem algorithm
        Octave编程环境代码：
            [W,s,v]=svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x');

2-单变量线性回归
    模型概述：
        监督学习：房价预测、肿瘤判断等
        单变量线性回归：只含有一个特征/输入变量
            数据集->学习算法拟合数据->构建模型预测数据

    代价函数概念
        数学定义
        训练集->选择参数->
            选择的参数决定了输出结果对于训练集、模型与实际值之间的差距，即建模误差。
            目标是选择出可以使得建模误差的平方和能够最小的模型参数
        代价函数（平方误差函数、平方误差代价函数）
    代价函数的直观理解
        三维空间展示、等高线图等
    梯度下降：用来求函数最小值
        思想：开始时随机选择一个参数的组合，计算代价函数，然后寻找下一个能让代价函数值下降最多的参数组合。
            持续这么做直到得到一个局部最小值。因为没有尝试完所有组合，所以不能确定是全局最小值。
        学习率
        参数更新：同时更新、同步更新
    梯度下降的直观理解
        接近局部最低，导数自动变小，梯度下降自动采取较小的幅度。
    平方误差函数结合梯度下降法以及平方代价函数=线性回归算法
    梯度下降的线性回归
        对于之前的线性回归问题运用梯度下降法，关键在于求出代价函数的导数。

3-线性代数回顾
    矩阵和向量
        矩阵维数即行数*列数
        矩阵元素（矩阵项）
        向量是一种特殊的矩阵
    加法和标量乘法
        矩阵加法：必须行列数相等，对应元素相加。
        矩阵乘法：每个元素都要乘。
        组合算法也类似
    矩阵向量乘法
        m*n矩阵乘以n*1向量，得到m*1向量
    矩阵乘法
        m*n矩阵乘以n*o矩阵，变成m*o矩阵
    矩阵乘法性质

    逆、转置

4-多变量线性回归
    多维特征
































